{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Skupper Tests - Ansible Project Overview This project provides a modular and scalable framework to test and manage Skupper environments using Ansible roles and scenarios. Each role targets a specific functionality in a Skupper-based architecture, offering flexibility, reliability, and adherence to Ansible best practices. The project includes detailed tests for every role to ensure a robust and maintainable solution. Key Roles 1. deploy_workload Purpose : Deploy backend and frontend workloads in specified namespaces. Tests : Verifies successful deployment and readiness of workloads in Kubernetes. 2. env_shakeout Purpose : Validates and prepares the Kubernetes environment for Skupper operations. Tests : Confirms cluster connectivity and ensures dependencies are available. 3. generate_namespaces Purpose : Creates namespaces with specific naming conventions to segment workloads and services. Tests : Validates namespace creation and ensures naming compliance. 4. install_skupper Purpose : Installs Skupper by applying CRDs and deploying its controller. Tests : Verifies the successful application of CRDs and controller readiness. 5. skupper_site Purpose : Configures Skupper sites, including advanced settings like linkAccess . Tests : Ensures manifests are applied correctly and that all pods are ready. 6. create_connector Purpose : Creates and deploys connectors for application routing in Skupper. Tests : Validates connector configuration and functionality. 7. expose_service Purpose : Exposes services in Kubernetes namespaces for external access. Tests : Confirms service exposure and connectivity. 8. access_grant Purpose : Manages access credentials for Skupper endpoints. Tests : Validates access token generation and usage. 9. create_listener Purpose : Configures listeners for consuming services via Skupper. Tests : Ensures listener setup and service consumption. 10. link_site Purpose : Establishes site links between Skupper instances. Tests : Confirms successful link creation and connectivity. 11. install_skupper_controller Purpose : Installs and configures the Skupper controller for advanced cluster settings. Tests : Verifies controller setup and operational readiness. 12. teardown_test Purpose : Cleans up namespaces and removes Skupper-related resources after testing. Tests : Ensures proper cleanup and verifies resource deletion. 13. run_curl Purpose : Runs a test to validate Skupper connectivity. Tests : Validates Skupper connectivity and service availability. Folder Structure skupper-tests/ \u251c\u2500\u2500 ansible.cfg # Ansible configuration file \u251c\u2500\u2500 Makefile # Automates tasks like dependency installation \u251c\u2500\u2500 .ansible-lint # Configuration for linting \u251c\u2500\u2500 .gitignore # Git ignore rules \u251c\u2500\u2500 LICENSE # License file \u251c\u2500\u2500 README.md # Documentation for the project \u251c\u2500\u2500 requirements.txt # Python dependencies \u251c\u2500\u2500 run_all_tests.sh # Script to execute all tests \u251c\u2500\u2500 scenarios/ # Example scenarios like hello-world \u2502 \u2514\u2500\u2500 hello-world/ \u2502 \u251c\u2500\u2500 hello-world.yml # Playbook for hello-world scenario \u2502 \u2514\u2500\u2500 inventory/ # Inventory for hello-world scenario \u2502 \u251c\u2500\u2500 hosts.yml \u2502 \u251c\u2500\u2500 group_vars/ # Group variables for hello-world scenario \u2502 \u2514\u2500\u2500 host_vars/ \u251c\u2500\u2500 test_results/ # Logs for test runs \u2514\u2500\u2500 collections/ \u251c\u2500\u2500 ansible_collections/ \u2502 \u2514\u2500\u2500 rhsiqe/ \u2502 \u2514\u2500\u2500 skupper/ \u2502 \u251c\u2500\u2500 galaxy.yml # Metadata for the collection \u2502 \u251c\u2500\u2500 README.md # Documentation for the collection \u2502 \u2514\u2500\u2500 roles/ \u2502 \u251c\u2500\u2500 access_grant/ \u2502 \u251c\u2500\u2500 create_listener/ \u2502 \u251c\u2500\u2500 deploy_workload/ \u2502 \u251c\u2500\u2500 env_shakeout/ \u2502 \u251c\u2500\u2500 create_connector/ \u2502 \u251c\u2500\u2500 expose_service/ \u2502 \u251c\u2500\u2500 generate_namespaces/ \u2502 \u251c\u2500\u2500 install_skupper/ \u2502 \u251c\u2500\u2500 install_skupper_controller/ \u2502 \u251c\u2500\u2500 link_site/ \u2502 \u251c\u2500\u2500 run_curl_test/ \u2502 \u251c\u2500\u2500 skupper_site/ \u2502 \u2514\u2500\u2500 teardown_test/ \u2514\u2500\u2500 requirements.yml # Collection dependencies Test Instructions Running Role-Specific Tests Each role has its own test playbook, allowing independent testing. For example, to test the access_grant role: ansible-playbook collections/ansible_collections/rhsiqe/skupper/roles/access_grant/tests/test_playbook.yml \\ -i collections/ansible_collections/rhsiqe/skupper/roles/access_grant/tests/inventory/hosts.yml The role tests will automatically invoke any dependent roles required to create the appropriate test scenario. Running All Tests Use the make tests command to run all tests in a logical order. This ensures the dependencies between roles are respected, and the environment is set up and torn down cleanly. The test script automatically logs results for review. Example: make tests The run_all_tests.sh script executes the roles in the following order: 1. env_shakeout 2. generate_namespaces 3. deploy_workload 4. install_skupper 5. install_skupper_controller 6. skupper_site 7. create_connector 8. create_listener 9. access_grant 10. link_site 11. expose_service 12. run_curl_test Test logs are stored in the test_results/ directory with timestamps. Usage Instructions Installing Dependencies Install Python and Ansible dependencies: bash make build Run the test suite: bash make tests Review test results in the test_results/ directory. Running Example Scenarios Navigate to a scenario directory and execute the playbook. For example, to run the hello-world scenario: ansible-playbook -i scenarios/hello-world/inventory/hosts.yml scenarios/hello-world/hello-world.yml Scenario test hello-world This scenario deploys a simple frontend and backend application in separate namespaces. The frontend consumes the backend service via Skupper. And it uses all the roles in the collection. Use as guide to create your own scenarios. Running the hello-world scenario After build the roles and collections, run the hello-world scenario: bash ansible-playbook scenarios/hello-world/hello-world.yml -i scenarios/hello-world/inventory/hosts.yml Running skipping skupper installation: bash ansible-playbook scenarios/hello-world/hello-world.yml -i scenarios/hello-world/inventory/hosts.yml -e skip_skupper_install=true Running skipping teardown: bash ansible-playbook scenarios/hello-world/hello-world.yml -i scenarios/hello-world/inventory/hosts.yml -e skip_teardown=true Debuging when needed (ensure that the teardown was skipped): The playbook creates a temporary folder under /tmp with the inventory name on it: TASK [Set a unique temporary directory path per host] ********************************************************************************************************************************************************************************************* task path: /home/rzago/Code/skupper-tests/scenarios/hello-world/hello-world.yml:4 ok: [west] => {\"ansible_facts\": {\"temp_dir_path\": \"/tmp/ansible.west\"}, \"changed\": false} ok: [east] => {\"ansible_facts\": {\"temp_dir_path\": \"/tmp/ansible.east\"}, \"changed\": false} Inside this folder you will find the logs and the inventory file used to run the playbook: \u276f ls -l /tmp/ansible.east total 8 -rw-r--r--. 1 rzago rzago 143 Nov 24 16:41 connector-east.yml # Connector file -rw-r--r--. 1 rzago rzago 113 Nov 24 16:41 skupper-site-east.yml # Skupper site file \u276f ls -l /tmp/ansible.west/ total 16 -rw-r--r--. 1 rzago rzago 132 Nov 24 16:41 access-grant-west.yml # Access grant -rw-r--r--. 1 rzago rzago 1454 Nov 24 16:42 access-token-west.yml # Access token file -rw-r--r--. 1 rzago rzago 134 Nov 24 16:41 consume-service-west.yml # Consume service file -rw-r--r--. 1 rzago rzago 141 Nov 24 16:41 skupper-site-west.yml # Skupper site file Compatibility Tested with : ansible-lint >= 24.2.0 Compatible with : ansible-core License This project is licensed under the Apache License 2.0. See the LICENSE for details.","title":"Home"},{"location":"#skupper-tests-ansible-project","text":"","title":"Skupper Tests - Ansible Project"},{"location":"#overview","text":"This project provides a modular and scalable framework to test and manage Skupper environments using Ansible roles and scenarios. Each role targets a specific functionality in a Skupper-based architecture, offering flexibility, reliability, and adherence to Ansible best practices. The project includes detailed tests for every role to ensure a robust and maintainable solution.","title":"Overview"},{"location":"#key-roles","text":"","title":"Key Roles"},{"location":"#1-deploy_workload","text":"Purpose : Deploy backend and frontend workloads in specified namespaces. Tests : Verifies successful deployment and readiness of workloads in Kubernetes.","title":"1. deploy_workload"},{"location":"#2-env_shakeout","text":"Purpose : Validates and prepares the Kubernetes environment for Skupper operations. Tests : Confirms cluster connectivity and ensures dependencies are available.","title":"2. env_shakeout"},{"location":"#3-generate_namespaces","text":"Purpose : Creates namespaces with specific naming conventions to segment workloads and services. Tests : Validates namespace creation and ensures naming compliance.","title":"3. generate_namespaces"},{"location":"#4-install_skupper","text":"Purpose : Installs Skupper by applying CRDs and deploying its controller. Tests : Verifies the successful application of CRDs and controller readiness.","title":"4. install_skupper"},{"location":"#5-skupper_site","text":"Purpose : Configures Skupper sites, including advanced settings like linkAccess . Tests : Ensures manifests are applied correctly and that all pods are ready.","title":"5. skupper_site"},{"location":"#6-create_connector","text":"Purpose : Creates and deploys connectors for application routing in Skupper. Tests : Validates connector configuration and functionality.","title":"6. create_connector"},{"location":"#7-expose_service","text":"Purpose : Exposes services in Kubernetes namespaces for external access. Tests : Confirms service exposure and connectivity.","title":"7. expose_service"},{"location":"#8-access_grant","text":"Purpose : Manages access credentials for Skupper endpoints. Tests : Validates access token generation and usage.","title":"8. access_grant"},{"location":"#9-create_listener","text":"Purpose : Configures listeners for consuming services via Skupper. Tests : Ensures listener setup and service consumption.","title":"9. create_listener"},{"location":"#10-link_site","text":"Purpose : Establishes site links between Skupper instances. Tests : Confirms successful link creation and connectivity.","title":"10. link_site"},{"location":"#11-install_skupper_controller","text":"Purpose : Installs and configures the Skupper controller for advanced cluster settings. Tests : Verifies controller setup and operational readiness.","title":"11. install_skupper_controller"},{"location":"#12-teardown_test","text":"Purpose : Cleans up namespaces and removes Skupper-related resources after testing. Tests : Ensures proper cleanup and verifies resource deletion.","title":"12. teardown_test"},{"location":"#13-run_curl","text":"Purpose : Runs a test to validate Skupper connectivity. Tests : Validates Skupper connectivity and service availability.","title":"13. run_curl"},{"location":"#folder-structure","text":"skupper-tests/ \u251c\u2500\u2500 ansible.cfg # Ansible configuration file \u251c\u2500\u2500 Makefile # Automates tasks like dependency installation \u251c\u2500\u2500 .ansible-lint # Configuration for linting \u251c\u2500\u2500 .gitignore # Git ignore rules \u251c\u2500\u2500 LICENSE # License file \u251c\u2500\u2500 README.md # Documentation for the project \u251c\u2500\u2500 requirements.txt # Python dependencies \u251c\u2500\u2500 run_all_tests.sh # Script to execute all tests \u251c\u2500\u2500 scenarios/ # Example scenarios like hello-world \u2502 \u2514\u2500\u2500 hello-world/ \u2502 \u251c\u2500\u2500 hello-world.yml # Playbook for hello-world scenario \u2502 \u2514\u2500\u2500 inventory/ # Inventory for hello-world scenario \u2502 \u251c\u2500\u2500 hosts.yml \u2502 \u251c\u2500\u2500 group_vars/ # Group variables for hello-world scenario \u2502 \u2514\u2500\u2500 host_vars/ \u251c\u2500\u2500 test_results/ # Logs for test runs \u2514\u2500\u2500 collections/ \u251c\u2500\u2500 ansible_collections/ \u2502 \u2514\u2500\u2500 rhsiqe/ \u2502 \u2514\u2500\u2500 skupper/ \u2502 \u251c\u2500\u2500 galaxy.yml # Metadata for the collection \u2502 \u251c\u2500\u2500 README.md # Documentation for the collection \u2502 \u2514\u2500\u2500 roles/ \u2502 \u251c\u2500\u2500 access_grant/ \u2502 \u251c\u2500\u2500 create_listener/ \u2502 \u251c\u2500\u2500 deploy_workload/ \u2502 \u251c\u2500\u2500 env_shakeout/ \u2502 \u251c\u2500\u2500 create_connector/ \u2502 \u251c\u2500\u2500 expose_service/ \u2502 \u251c\u2500\u2500 generate_namespaces/ \u2502 \u251c\u2500\u2500 install_skupper/ \u2502 \u251c\u2500\u2500 install_skupper_controller/ \u2502 \u251c\u2500\u2500 link_site/ \u2502 \u251c\u2500\u2500 run_curl_test/ \u2502 \u251c\u2500\u2500 skupper_site/ \u2502 \u2514\u2500\u2500 teardown_test/ \u2514\u2500\u2500 requirements.yml # Collection dependencies","title":"Folder Structure"},{"location":"#test-instructions","text":"","title":"Test Instructions"},{"location":"#running-role-specific-tests","text":"Each role has its own test playbook, allowing independent testing. For example, to test the access_grant role: ansible-playbook collections/ansible_collections/rhsiqe/skupper/roles/access_grant/tests/test_playbook.yml \\ -i collections/ansible_collections/rhsiqe/skupper/roles/access_grant/tests/inventory/hosts.yml The role tests will automatically invoke any dependent roles required to create the appropriate test scenario.","title":"Running Role-Specific Tests"},{"location":"#running-all-tests","text":"Use the make tests command to run all tests in a logical order. This ensures the dependencies between roles are respected, and the environment is set up and torn down cleanly. The test script automatically logs results for review.","title":"Running All Tests"},{"location":"#example","text":"make tests The run_all_tests.sh script executes the roles in the following order: 1. env_shakeout 2. generate_namespaces 3. deploy_workload 4. install_skupper 5. install_skupper_controller 6. skupper_site 7. create_connector 8. create_listener 9. access_grant 10. link_site 11. expose_service 12. run_curl_test Test logs are stored in the test_results/ directory with timestamps.","title":"Example:"},{"location":"#usage-instructions","text":"","title":"Usage Instructions"},{"location":"#installing-dependencies","text":"Install Python and Ansible dependencies: bash make build Run the test suite: bash make tests Review test results in the test_results/ directory.","title":"Installing Dependencies"},{"location":"#running-example-scenarios","text":"Navigate to a scenario directory and execute the playbook. For example, to run the hello-world scenario: ansible-playbook -i scenarios/hello-world/inventory/hosts.yml scenarios/hello-world/hello-world.yml","title":"Running Example Scenarios"},{"location":"#scenario-test-hello-world","text":"This scenario deploys a simple frontend and backend application in separate namespaces. The frontend consumes the backend service via Skupper. And it uses all the roles in the collection. Use as guide to create your own scenarios.","title":"Scenario test hello-world"},{"location":"#running-the-hello-world-scenario","text":"After build the roles and collections, run the hello-world scenario: bash ansible-playbook scenarios/hello-world/hello-world.yml -i scenarios/hello-world/inventory/hosts.yml Running skipping skupper installation: bash ansible-playbook scenarios/hello-world/hello-world.yml -i scenarios/hello-world/inventory/hosts.yml -e skip_skupper_install=true Running skipping teardown: bash ansible-playbook scenarios/hello-world/hello-world.yml -i scenarios/hello-world/inventory/hosts.yml -e skip_teardown=true","title":"Running the hello-world scenario"},{"location":"#debuging-when-needed-ensure-that-the-teardown-was-skipped","text":"The playbook creates a temporary folder under /tmp with the inventory name on it: TASK [Set a unique temporary directory path per host] ********************************************************************************************************************************************************************************************* task path: /home/rzago/Code/skupper-tests/scenarios/hello-world/hello-world.yml:4 ok: [west] => {\"ansible_facts\": {\"temp_dir_path\": \"/tmp/ansible.west\"}, \"changed\": false} ok: [east] => {\"ansible_facts\": {\"temp_dir_path\": \"/tmp/ansible.east\"}, \"changed\": false} Inside this folder you will find the logs and the inventory file used to run the playbook: \u276f ls -l /tmp/ansible.east total 8 -rw-r--r--. 1 rzago rzago 143 Nov 24 16:41 connector-east.yml # Connector file -rw-r--r--. 1 rzago rzago 113 Nov 24 16:41 skupper-site-east.yml # Skupper site file \u276f ls -l /tmp/ansible.west/ total 16 -rw-r--r--. 1 rzago rzago 132 Nov 24 16:41 access-grant-west.yml # Access grant -rw-r--r--. 1 rzago rzago 1454 Nov 24 16:42 access-token-west.yml # Access token file -rw-r--r--. 1 rzago rzago 134 Nov 24 16:41 consume-service-west.yml # Consume service file -rw-r--r--. 1 rzago rzago 141 Nov 24 16:41 skupper-site-west.yml # Skupper site file","title":"Debuging when needed (ensure that the teardown was skipped):"},{"location":"#compatibility","text":"Tested with : ansible-lint >= 24.2.0 Compatible with : ansible-core","title":"Compatibility"},{"location":"#license","text":"This project is licensed under the Apache License 2.0. See the LICENSE for details.","title":"License"},{"location":"roles/access_grant/","text":"Role: access_grant This Ansible role automates the creation and management of AccessGrant and AccessToken resources in a Kubernetes cluster using the Skupper API. It ensures the generation of manifests from templates, applies them to the cluster, and waits for the resources to reach a ready state. Tasks Generate AccessGrant and AccessToken Manifests: Renders manifests from Jinja2 templates for AccessGrant and AccessToken resources. Apply Manifests to Kubernetes Cluster: Uses kubernetes.core.k8s to apply the generated manifests. Monitor Resource State: Waits for AccessGrant to be ready and verifies the state of pods in the namespace. Extract Resource Details: Captures the details of the created AccessGrant and outputs relevant data for further use. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Skupper installed and configured in the target namespaces Role Variables Variable Default Value Description access_grant_name my-grant Name of the AccessGrant resource. access_grant_redemptions_allowed 10 Number of redemptions allowed for the AccessGrant . access_grant_expiration_window 1h Expiration window for the AccessGrant . access_grant_state present Desired state of the AccessGrant resource ( present or absent ). access_grant_template access-grant.yml.j2 Path to the Jinja2 template for AccessGrant . access_grant_token_template access_token.yml.j2 Path to the Jinja2 template for AccessToken . access_grant_output_path /tmp/localhost Directory where the generated manifest files will be stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for cluster access. Example Usage Playbook - hosts: all tasks: - name: Include the access_grant role ansible.builtin.include_role: name: rhsiqe.skupper.access_grant vars: namespace_prefix: \"skupper\" namespace_name: \"east\" access_grant_name: \"my-access-grant\" access_grant_redemptions_allowed: 5 access_grant_expiration_window: \"2h\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . Generated manifests are stored in the access_grant_output_path directory, named according to the inventory host. The AccessGrant details (e.g., ca , code , and url ) are captured and available for further use. Ensure that the kubernetes.core collection is installed to use the kubernetes.core.k8s module. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Access Grant"},{"location":"roles/access_grant/#role-access_grant","text":"This Ansible role automates the creation and management of AccessGrant and AccessToken resources in a Kubernetes cluster using the Skupper API. It ensures the generation of manifests from templates, applies them to the cluster, and waits for the resources to reach a ready state.","title":"Role: access_grant"},{"location":"roles/access_grant/#tasks","text":"Generate AccessGrant and AccessToken Manifests: Renders manifests from Jinja2 templates for AccessGrant and AccessToken resources. Apply Manifests to Kubernetes Cluster: Uses kubernetes.core.k8s to apply the generated manifests. Monitor Resource State: Waits for AccessGrant to be ready and verifies the state of pods in the namespace. Extract Resource Details: Captures the details of the created AccessGrant and outputs relevant data for further use.","title":"Tasks"},{"location":"roles/access_grant/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Skupper installed and configured in the target namespaces","title":"Requirements"},{"location":"roles/access_grant/#role-variables","text":"Variable Default Value Description access_grant_name my-grant Name of the AccessGrant resource. access_grant_redemptions_allowed 10 Number of redemptions allowed for the AccessGrant . access_grant_expiration_window 1h Expiration window for the AccessGrant . access_grant_state present Desired state of the AccessGrant resource ( present or absent ). access_grant_template access-grant.yml.j2 Path to the Jinja2 template for AccessGrant . access_grant_token_template access_token.yml.j2 Path to the Jinja2 template for AccessToken . access_grant_output_path /tmp/localhost Directory where the generated manifest files will be stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for cluster access.","title":"Role Variables"},{"location":"roles/access_grant/#example-usage","text":"","title":"Example Usage"},{"location":"roles/access_grant/#playbook","text":"- hosts: all tasks: - name: Include the access_grant role ansible.builtin.include_role: name: rhsiqe.skupper.access_grant vars: namespace_prefix: \"skupper\" namespace_name: \"east\" access_grant_name: \"my-access-grant\" access_grant_redemptions_allowed: 5 access_grant_expiration_window: \"2h\"","title":"Playbook"},{"location":"roles/access_grant/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/access_grant/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/access_grant/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/access_grant/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . Generated manifests are stored in the access_grant_output_path directory, named according to the inventory host. The AccessGrant details (e.g., ca , code , and url ) are captured and available for further use. Ensure that the kubernetes.core collection is installed to use the kubernetes.core.k8s module.","title":"Notes"},{"location":"roles/access_grant/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/create_connector/","text":"Role: create_connector This Ansible role automates the creation and management of Connector resources in a Kubernetes cluster using the Skupper API. It generates a manifest for the Connector resource based on a template, applies it to the target namespace, and optionally debugs the results. Tasks Set Manifest File Path: Determines the file path for the Connector manifest based on the inventory host. Delete Existing Connector Manifest: Removes any existing manifest file to ensure a clean state. Render Connector Manifest: Creates a Kubernetes manifest for the Connector resource using a Jinja2 template. Apply Manifest to Kubernetes: Uses the kubernetes.core.k8s module to apply the manifest to the specified namespace. Debug Application Results: Outputs the results of the applied Connector resource for verification. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Skupper installed and configured in the target namespaces Role Variables Variable Default Value Description create_connector_routing_key backend Routing key for the Connector . create_connector_metadata_name backend Metadata name for the Connector . create_connector_port 8080 Port for the Connector . create_connector_selector app=backend Selector for the Connector . create_connector_manifest_template connector.yml.j2 Jinja2 template for the Connector manifest. create_connector_state present Desired state of the resource ( present or absent ). create_connector_output_path /tmp/localhost Directory where the manifest file will be stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for cluster access. Example Usage Playbook - hosts: all tasks: - name: Expose a backend connector ansible.builtin.include_role: name: rhsiqe.skupper.create_connector vars: namespace_prefix: \"skupper\" namespace_name: \"east\" create_connector_routing_key: \"frontend\" create_connector_metadata_name: \"frontend-connector\" create_connector_port: 9090 create_connector_selector: \"app=frontend\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . The generated manifest file is stored in the create_connector_output_path directory, named according to the inventory host. Ensure the kubernetes.core.k8s module is installed to use this role. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Create Connector"},{"location":"roles/create_connector/#role-create_connector","text":"This Ansible role automates the creation and management of Connector resources in a Kubernetes cluster using the Skupper API. It generates a manifest for the Connector resource based on a template, applies it to the target namespace, and optionally debugs the results.","title":"Role: create_connector"},{"location":"roles/create_connector/#tasks","text":"Set Manifest File Path: Determines the file path for the Connector manifest based on the inventory host. Delete Existing Connector Manifest: Removes any existing manifest file to ensure a clean state. Render Connector Manifest: Creates a Kubernetes manifest for the Connector resource using a Jinja2 template. Apply Manifest to Kubernetes: Uses the kubernetes.core.k8s module to apply the manifest to the specified namespace. Debug Application Results: Outputs the results of the applied Connector resource for verification.","title":"Tasks"},{"location":"roles/create_connector/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Skupper installed and configured in the target namespaces","title":"Requirements"},{"location":"roles/create_connector/#role-variables","text":"Variable Default Value Description create_connector_routing_key backend Routing key for the Connector . create_connector_metadata_name backend Metadata name for the Connector . create_connector_port 8080 Port for the Connector . create_connector_selector app=backend Selector for the Connector . create_connector_manifest_template connector.yml.j2 Jinja2 template for the Connector manifest. create_connector_state present Desired state of the resource ( present or absent ). create_connector_output_path /tmp/localhost Directory where the manifest file will be stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for cluster access.","title":"Role Variables"},{"location":"roles/create_connector/#example-usage","text":"","title":"Example Usage"},{"location":"roles/create_connector/#playbook","text":"- hosts: all tasks: - name: Expose a backend connector ansible.builtin.include_role: name: rhsiqe.skupper.create_connector vars: namespace_prefix: \"skupper\" namespace_name: \"east\" create_connector_routing_key: \"frontend\" create_connector_metadata_name: \"frontend-connector\" create_connector_port: 9090 create_connector_selector: \"app=frontend\"","title":"Playbook"},{"location":"roles/create_connector/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/create_connector/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/create_connector/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/create_connector/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . The generated manifest file is stored in the create_connector_output_path directory, named according to the inventory host. Ensure the kubernetes.core.k8s module is installed to use this role.","title":"Notes"},{"location":"roles/create_connector/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/create_listener/","text":"Role: create_listener This Ansible role automates the creation and management of Listener resources in a Kubernetes cluster using the Skupper API. It generates a manifest for the Listener resource from a template, applies it to the target namespace, and verifies the results. Tasks Generate Listener Manifest: Creates a Kubernetes manifest for the Listener resource using a Jinja2 template. Apply Manifest to Kubernetes Cluster: Uses the kubernetes.core.k8s module to apply the manifest in the specified namespace. Debug Applied Results: Outputs the results of the applied Listener for verification. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Skupper installed and configured in the target namespaces Role Variables Variable Default Value Description create_listener_metadata_name backend Name of the Listener resource. create_listener_routing_key backend Routing key for the Listener . create_listener_port 8080 Port on which the service listens. create_listener_host backend Hostname or service backend. create_listener_manifest_template listener.yml.j2 Jinja2 template for generating the Listener manifest. create_listener_state present Desired state of the Listener resource ( present or absent ). create_listener_output_path /tmp/localhost Directory where the generated manifest files are stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for cluster access. Example Usage Playbook - hosts: all tasks: - name: Include the create_listener role ansible.builtin.include_role: name: rhsiqe.skupper.create_listener vars: namespace_prefix: \"skupper\" namespace_name: \"east\" create_listener_metadata_name: \"frontend\" create_listener_routing_key: \"frontend\" create_listener_port: 9090 create_listener_host: \"frontend-service\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . Generated manifests are stored in the create_listener_output_path directory, named according to the inventory host. Ensure the kubernetes.core collection is installed to use the kubernetes.core.k8s module. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Create Listener"},{"location":"roles/create_listener/#role-create_listener","text":"This Ansible role automates the creation and management of Listener resources in a Kubernetes cluster using the Skupper API. It generates a manifest for the Listener resource from a template, applies it to the target namespace, and verifies the results.","title":"Role: create_listener"},{"location":"roles/create_listener/#tasks","text":"Generate Listener Manifest: Creates a Kubernetes manifest for the Listener resource using a Jinja2 template. Apply Manifest to Kubernetes Cluster: Uses the kubernetes.core.k8s module to apply the manifest in the specified namespace. Debug Applied Results: Outputs the results of the applied Listener for verification.","title":"Tasks"},{"location":"roles/create_listener/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Skupper installed and configured in the target namespaces","title":"Requirements"},{"location":"roles/create_listener/#role-variables","text":"Variable Default Value Description create_listener_metadata_name backend Name of the Listener resource. create_listener_routing_key backend Routing key for the Listener . create_listener_port 8080 Port on which the service listens. create_listener_host backend Hostname or service backend. create_listener_manifest_template listener.yml.j2 Jinja2 template for generating the Listener manifest. create_listener_state present Desired state of the Listener resource ( present or absent ). create_listener_output_path /tmp/localhost Directory where the generated manifest files are stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for cluster access.","title":"Role Variables"},{"location":"roles/create_listener/#example-usage","text":"","title":"Example Usage"},{"location":"roles/create_listener/#playbook","text":"- hosts: all tasks: - name: Include the create_listener role ansible.builtin.include_role: name: rhsiqe.skupper.create_listener vars: namespace_prefix: \"skupper\" namespace_name: \"east\" create_listener_metadata_name: \"frontend\" create_listener_routing_key: \"frontend\" create_listener_port: 9090 create_listener_host: \"frontend-service\"","title":"Playbook"},{"location":"roles/create_listener/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/create_listener/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/create_listener/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/create_listener/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . Generated manifests are stored in the create_listener_output_path directory, named according to the inventory host. Ensure the kubernetes.core collection is installed to use the kubernetes.core.k8s module.","title":"Notes"},{"location":"roles/create_listener/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/deploy_job/","text":"Role: deploy_job This Ansible role automates the deployment of a job in a Kubernetes cluster. It creates a Job resource in the specified namespace, waits for the job to be ready, and displays the running pods for verification. Tasks Set Namespace: Derives the namespace based on the prefix and name variables. Deploy Job: Creates a Job resource with the container image and job command. Wait for Job Readiness: Ensures the workload is running by verifying pod statuses. Display Pod Information: Outputs the names of the running pods for the deployed workload. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Default Value Description deploy_job_namespace_name default Namespace where the job will be deployed. deploy_job_job_command \"\" - Commented out Command to run in the container initialization. If not in use, keep it commented out deploy_job_job_name jobname Job name. deploy_job_job_image Container image to use for the deployment. Must be defined in playbook/inventory. deploy_job_restart_policy OnFailure Job Restart Policy deploy_job_dns_policy ClusterFirst Job DNS Policy deploy_job_output_path /tmp/localhost Path to store any outputs (currently unused, reserved for future use). namespace_prefix Prefix for the namespace (defined in inventory or playbook). namespace_name Name of the namespace (defined in inventory or playbook). kubeconfig Path to the kubeconfig file for cluster access. Example Usage Playbook - hosts: all tasks: - name: Deploy a job in the specified namespace ansible.builtin.include_role: name: rhsiqe.skupper.deploy_job vars: namespace_prefix: \"skupper\" namespace_name: \"east\" deploy_job_job_name: \"my-job\" deploy_job_job_image: \"nginx:latest\" deploy_job_restart_policy: OnFailure deploy_job_dns_policy: ClusterFirst Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure deploy_job_job_image is defined in the playbook or inventory as it is mandatory for the deployment. Pods will be verified to ensure they are in the Running state. The kubernetes.core.k8s module is used for all Kubernetes operations, requiring the kubernetes.core collection to be installed. If the job does not requires any command to be executed in the initalization, you can keep the variable deploy_job_job_command commented out. Or you can set it, like this : deploy_job_job_command: iperf3 \"-s\" License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Deploy Job"},{"location":"roles/deploy_job/#role-deploy_job","text":"This Ansible role automates the deployment of a job in a Kubernetes cluster. It creates a Job resource in the specified namespace, waits for the job to be ready, and displays the running pods for verification.","title":"Role: deploy_job"},{"location":"roles/deploy_job/#tasks","text":"Set Namespace: Derives the namespace based on the prefix and name variables. Deploy Job: Creates a Job resource with the container image and job command. Wait for Job Readiness: Ensures the workload is running by verifying pod statuses. Display Pod Information: Outputs the names of the running pods for the deployed workload.","title":"Tasks"},{"location":"roles/deploy_job/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/deploy_job/#role-variables","text":"Variable Default Value Description deploy_job_namespace_name default Namespace where the job will be deployed. deploy_job_job_command \"\" - Commented out Command to run in the container initialization. If not in use, keep it commented out deploy_job_job_name jobname Job name. deploy_job_job_image Container image to use for the deployment. Must be defined in playbook/inventory. deploy_job_restart_policy OnFailure Job Restart Policy deploy_job_dns_policy ClusterFirst Job DNS Policy deploy_job_output_path /tmp/localhost Path to store any outputs (currently unused, reserved for future use). namespace_prefix Prefix for the namespace (defined in inventory or playbook). namespace_name Name of the namespace (defined in inventory or playbook). kubeconfig Path to the kubeconfig file for cluster access.","title":"Role Variables"},{"location":"roles/deploy_job/#example-usage","text":"","title":"Example Usage"},{"location":"roles/deploy_job/#playbook","text":"- hosts: all tasks: - name: Deploy a job in the specified namespace ansible.builtin.include_role: name: rhsiqe.skupper.deploy_job vars: namespace_prefix: \"skupper\" namespace_name: \"east\" deploy_job_job_name: \"my-job\" deploy_job_job_image: \"nginx:latest\" deploy_job_restart_policy: OnFailure deploy_job_dns_policy: ClusterFirst","title":"Playbook"},{"location":"roles/deploy_job/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/deploy_job/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/deploy_job/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/deploy_job/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure deploy_job_job_image is defined in the playbook or inventory as it is mandatory for the deployment. Pods will be verified to ensure they are in the Running state. The kubernetes.core.k8s module is used for all Kubernetes operations, requiring the kubernetes.core collection to be installed. If the job does not requires any command to be executed in the initalization, you can keep the variable deploy_job_job_command commented out. Or you can set it, like this : deploy_job_job_command: iperf3 \"-s\"","title":"Notes"},{"location":"roles/deploy_job/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/deploy_workload/","text":"Role: deploy_workload This Ansible role automates the deployment of a workload in a Kubernetes cluster. It creates a Deployment resource in the specified namespace, waits for the workload to be ready, and displays the running pods for verification. Tasks Set Namespace: Derives the namespace based on the prefix and name variables. Deploy Workload: Creates a Deployment resource with the specified replicas and container image. Wait for Deployment Readiness: Ensures the workload is running by verifying pod statuses. Based on the label app: Based on the number of replicas: Display Pod Information: Outputs the names of the running pods for the deployed workload. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Default Value Description deploy_workload_namespace_name default Namespace where the workload will be deployed. deploy_workload_deployment_command \"\" - Commented out Command to run in the container initialization. If not in use, keep it commented out deploy_workload_deployment_name app Name of the deployment. deploy_workload_replicas 1 Number of replicas for the workload. deploy_workload_workload_image Container image to use for the deployment. Must be defined in playbook/inventory. deploy_workload_output_path /tmp/localhost Path to store any outputs (currently unused, reserved for future use). namespace_prefix Prefix for the namespace (defined in inventory or playbook). namespace_name Name of the namespace (defined in inventory or playbook). kubeconfig Path to the kubeconfig file for cluster access. Example Usage Playbook - hosts: all tasks: - name: Deploy a workload in the specified namespace ansible.builtin.include_role: name: rhsiqe.skupper.deploy_workload vars: namespace_prefix: \"skupper\" namespace_name: \"east\" deploy_workload_deployment_name: \"my-app\" deploy_workload_replicas: 3 deploy_workload_workload_image: \"nginx:latest\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure deploy_workload_workload_image is defined in the playbook or inventory as it is mandatory for the deployment. Pods will be verified to ensure they are in the Running state. The kubernetes.core.k8s module is used for all Kubernetes operations, requiring the kubernetes.core collection to be installed. If the workload does not requires any command to be executed in the initalization, you can keep the variable deploy_workload_deployment_command commented out. Or you can set it, like this : deploy_workload_deployment_command: iperf3 \"-s\" License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Deploy Workload"},{"location":"roles/deploy_workload/#role-deploy_workload","text":"This Ansible role automates the deployment of a workload in a Kubernetes cluster. It creates a Deployment resource in the specified namespace, waits for the workload to be ready, and displays the running pods for verification.","title":"Role: deploy_workload"},{"location":"roles/deploy_workload/#tasks","text":"Set Namespace: Derives the namespace based on the prefix and name variables. Deploy Workload: Creates a Deployment resource with the specified replicas and container image. Wait for Deployment Readiness: Ensures the workload is running by verifying pod statuses. Based on the label app: Based on the number of replicas: Display Pod Information: Outputs the names of the running pods for the deployed workload.","title":"Tasks"},{"location":"roles/deploy_workload/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/deploy_workload/#role-variables","text":"Variable Default Value Description deploy_workload_namespace_name default Namespace where the workload will be deployed. deploy_workload_deployment_command \"\" - Commented out Command to run in the container initialization. If not in use, keep it commented out deploy_workload_deployment_name app Name of the deployment. deploy_workload_replicas 1 Number of replicas for the workload. deploy_workload_workload_image Container image to use for the deployment. Must be defined in playbook/inventory. deploy_workload_output_path /tmp/localhost Path to store any outputs (currently unused, reserved for future use). namespace_prefix Prefix for the namespace (defined in inventory or playbook). namespace_name Name of the namespace (defined in inventory or playbook). kubeconfig Path to the kubeconfig file for cluster access.","title":"Role Variables"},{"location":"roles/deploy_workload/#example-usage","text":"","title":"Example Usage"},{"location":"roles/deploy_workload/#playbook","text":"- hosts: all tasks: - name: Deploy a workload in the specified namespace ansible.builtin.include_role: name: rhsiqe.skupper.deploy_workload vars: namespace_prefix: \"skupper\" namespace_name: \"east\" deploy_workload_deployment_name: \"my-app\" deploy_workload_replicas: 3 deploy_workload_workload_image: \"nginx:latest\"","title":"Playbook"},{"location":"roles/deploy_workload/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/deploy_workload/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/deploy_workload/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/deploy_workload/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure deploy_workload_workload_image is defined in the playbook or inventory as it is mandatory for the deployment. Pods will be verified to ensure they are in the Running state. The kubernetes.core.k8s module is used for all Kubernetes operations, requiring the kubernetes.core collection to be installed. If the workload does not requires any command to be executed in the initalization, you can keep the variable deploy_workload_deployment_command commented out. Or you can set it, like this : deploy_workload_deployment_command: iperf3 \"-s\"","title":"Notes"},{"location":"roles/deploy_workload/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/env_shakeout/","text":"Role: env_shakeout This Ansible role performs a shakeout test for a Kubernetes environment. It verifies cluster connectivity and optionally debugs the inventory variables for each host. Tasks Debug Host Variables: Outputs all host variables for the current inventory host when debugging is enabled. Verify Cluster Connection: Checks the connection to the Kubernetes cluster by listing nodes. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Default Value Description env_shakeout_debug false Whether to debug and output all inventory variables for the host. kubeconfig Path to the kubeconfig file for accessing the cluster. Mandatory. Example Usage Playbook - hosts: all tasks: - name: Perform an environment shakeout test ansible.builtin.include_role: name: rhsiqe.skupper.env_shakeout vars: env_shakeout_debug: true Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig west.yml kubeconfig: /path/to/west/kubeconfig Notes If env_shakeout_debug is set to true , all inventory variables for the current host will be displayed. The role uses the kubernetes.core.k8s_info module to list cluster nodes, confirming connectivity to the Kubernetes API. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Environment Shakeout"},{"location":"roles/env_shakeout/#role-env_shakeout","text":"This Ansible role performs a shakeout test for a Kubernetes environment. It verifies cluster connectivity and optionally debugs the inventory variables for each host.","title":"Role: env_shakeout"},{"location":"roles/env_shakeout/#tasks","text":"Debug Host Variables: Outputs all host variables for the current inventory host when debugging is enabled. Verify Cluster Connection: Checks the connection to the Kubernetes cluster by listing nodes.","title":"Tasks"},{"location":"roles/env_shakeout/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/env_shakeout/#role-variables","text":"Variable Default Value Description env_shakeout_debug false Whether to debug and output all inventory variables for the host. kubeconfig Path to the kubeconfig file for accessing the cluster. Mandatory.","title":"Role Variables"},{"location":"roles/env_shakeout/#example-usage","text":"","title":"Example Usage"},{"location":"roles/env_shakeout/#playbook","text":"- hosts: all tasks: - name: Perform an environment shakeout test ansible.builtin.include_role: name: rhsiqe.skupper.env_shakeout vars: env_shakeout_debug: true","title":"Playbook"},{"location":"roles/env_shakeout/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/env_shakeout/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig","title":"east.yml"},{"location":"roles/env_shakeout/#westyml","text":"kubeconfig: /path/to/west/kubeconfig","title":"west.yml"},{"location":"roles/env_shakeout/#notes","text":"If env_shakeout_debug is set to true , all inventory variables for the current host will be displayed. The role uses the kubernetes.core.k8s_info module to list cluster nodes, confirming connectivity to the Kubernetes API.","title":"Notes"},{"location":"roles/env_shakeout/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/expose_service/","text":"Role: expose_service The expose_service Ansible role automates the creation of Kubernetes Service resources to expose deployments within a cluster or to external clients. It supports various service types, including ClusterIP , NodePort , and LoadBalancer . Tasks Set Namespace: Determines the namespace where the service will be created based on the prefix and name variables. Expose Deployment: Creates or updates a Kubernetes Service to expose a deployment on the specified port. Debug Service Creation Result: Outputs the result of the service creation for verification. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Default Value Description expose_service_name frontend Name of the service to expose. expose_service_port 8080 External port exposed by the service. expose_service_target_port 8080 Target port on the deployment. expose_service_type LoadBalancer Service type ( ClusterIP , NodePort , or LoadBalancer ). namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. Mandatory. Example Usage Playbook - hosts: all tasks: - name: Expose a service in the specified namespace ansible.builtin.include_role: name: rhsiqe.skupper.expose_service vars: namespace_prefix: \"skupper\" namespace_name: \"east\" expose_service_name: \"frontend\" expose_service_port: 9090 expose_service_target_port: 9090 expose_service_type: \"NodePort\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure that the deployment selector matches the app label used in the Service definition. The role uses the kubernetes.core.k8s module, which requires the kubernetes.core collection to be installed. License This project is licensed under the Apache License, Version 2.0. See the LICENSE for details.","title":"Expose Service"},{"location":"roles/expose_service/#role-expose_service","text":"The expose_service Ansible role automates the creation of Kubernetes Service resources to expose deployments within a cluster or to external clients. It supports various service types, including ClusterIP , NodePort , and LoadBalancer .","title":"Role: expose_service"},{"location":"roles/expose_service/#tasks","text":"Set Namespace: Determines the namespace where the service will be created based on the prefix and name variables. Expose Deployment: Creates or updates a Kubernetes Service to expose a deployment on the specified port. Debug Service Creation Result: Outputs the result of the service creation for verification.","title":"Tasks"},{"location":"roles/expose_service/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/expose_service/#role-variables","text":"Variable Default Value Description expose_service_name frontend Name of the service to expose. expose_service_port 8080 External port exposed by the service. expose_service_target_port 8080 Target port on the deployment. expose_service_type LoadBalancer Service type ( ClusterIP , NodePort , or LoadBalancer ). namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. Mandatory.","title":"Role Variables"},{"location":"roles/expose_service/#example-usage","text":"","title":"Example Usage"},{"location":"roles/expose_service/#playbook","text":"- hosts: all tasks: - name: Expose a service in the specified namespace ansible.builtin.include_role: name: rhsiqe.skupper.expose_service vars: namespace_prefix: \"skupper\" namespace_name: \"east\" expose_service_name: \"frontend\" expose_service_port: 9090 expose_service_target_port: 9090 expose_service_type: \"NodePort\"","title":"Playbook"},{"location":"roles/expose_service/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/expose_service/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/expose_service/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/expose_service/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure that the deployment selector matches the app label used in the Service definition. The role uses the kubernetes.core.k8s module, which requires the kubernetes.core collection to be installed.","title":"Notes"},{"location":"roles/expose_service/#license","text":"This project is licensed under the Apache License, Version 2.0. See the LICENSE for details.","title":"License"},{"location":"roles/generate_namespaces/","text":"Role: generate_namespaces This Ansible role creates Kubernetes namespaces using a specified prefix and name. It ensures the namespace is created in the target cluster and displays its details for verification. Tasks Create Namespace: Uses the kubernetes.core.k8s module to create a Kubernetes namespace with the specified name. Display Namespace Details: Outputs the name of the created namespace for confirmation. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Description namespace_prefix Prefix for the namespace. namespace_name Base name for the namespace. kubeconfig Path to the kubeconfig file for accessing the cluster. Mandatory. Example Usage Playbook - hosts: all tasks: - name: Generate namespaces ansible.builtin.include_role: name: rhsiqe.skupper.generate_namespaces vars: namespace_prefix: \"skupper\" namespace_name: \"east\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is created as <namespace_prefix>-<namespace_name> . Ensure the kubernetes.core.k8s module is installed to use this role. The task outputs the namespace details for verification. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Generate Namespaces"},{"location":"roles/generate_namespaces/#role-generate_namespaces","text":"This Ansible role creates Kubernetes namespaces using a specified prefix and name. It ensures the namespace is created in the target cluster and displays its details for verification.","title":"Role: generate_namespaces"},{"location":"roles/generate_namespaces/#tasks","text":"Create Namespace: Uses the kubernetes.core.k8s module to create a Kubernetes namespace with the specified name. Display Namespace Details: Outputs the name of the created namespace for confirmation.","title":"Tasks"},{"location":"roles/generate_namespaces/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/generate_namespaces/#role-variables","text":"Variable Description namespace_prefix Prefix for the namespace. namespace_name Base name for the namespace. kubeconfig Path to the kubeconfig file for accessing the cluster. Mandatory.","title":"Role Variables"},{"location":"roles/generate_namespaces/#example-usage","text":"","title":"Example Usage"},{"location":"roles/generate_namespaces/#playbook","text":"- hosts: all tasks: - name: Generate namespaces ansible.builtin.include_role: name: rhsiqe.skupper.generate_namespaces vars: namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"Playbook"},{"location":"roles/generate_namespaces/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/generate_namespaces/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/generate_namespaces/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/generate_namespaces/#notes","text":"The namespace is created as <namespace_prefix>-<namespace_name> . Ensure the kubernetes.core.k8s module is installed to use this role. The task outputs the namespace details for verification.","title":"Notes"},{"location":"roles/generate_namespaces/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/host_setup/","text":"Role: host_setup This Ansible role installs helm on target hosts to prepare them for managing Kubernetes deployments. The role ensures that the Helm package is installed and up to date. Tasks Install Helm: Installs the package using the script when the package is not available in the default package manager. Requirements Ansible 2.9 or newer Elevated privileges (e.g., become: true ) on the target hosts to install packages. The target hosts must support the installation of helm via their default package manager. Role Variables This role does not require any additional variables to function. It uses default settings to install the helm package. However, you can customize it if needed by overriding variables related to package management. Example Usage Include the role in your playbook to install helm on target hosts: Playbook - hosts: all become: true tasks: - name: Set up the host with helm ansible.builtin.include_role: name: rhsiqe.skupper.host_setup Inventory Ensure that the target hosts are correctly defined in the inventory: inventory/hosts.yml all: hosts: target_host_1: ansible_host: 192.168.1.100 target_host_2: ansible_host: 192.168.1.101 inventory/group_vars/all.yml ansible_user: your_user ansible_ssh_private_key_file: /path/to/ssh/key Notes The role uses the ansible.builtin.package module for installing helm , which ensures compatibility with the package manager of the target operating system. If you require specific Helm versions or additional configurations, you can extend this role or override variables in your playbook or inventory. Test this role using the included tests/test_playbook.yml to verify functionality before deploying to production. License Apache License 2.0","title":"Host Setup"},{"location":"roles/host_setup/#role-host_setup","text":"This Ansible role installs helm on target hosts to prepare them for managing Kubernetes deployments. The role ensures that the Helm package is installed and up to date.","title":"Role: host_setup"},{"location":"roles/host_setup/#tasks","text":"Install Helm: Installs the package using the script when the package is not available in the default package manager.","title":"Tasks"},{"location":"roles/host_setup/#requirements","text":"Ansible 2.9 or newer Elevated privileges (e.g., become: true ) on the target hosts to install packages. The target hosts must support the installation of helm via their default package manager.","title":"Requirements"},{"location":"roles/host_setup/#role-variables","text":"This role does not require any additional variables to function. It uses default settings to install the helm package. However, you can customize it if needed by overriding variables related to package management.","title":"Role Variables"},{"location":"roles/host_setup/#example-usage","text":"Include the role in your playbook to install helm on target hosts:","title":"Example Usage"},{"location":"roles/host_setup/#playbook","text":"- hosts: all become: true tasks: - name: Set up the host with helm ansible.builtin.include_role: name: rhsiqe.skupper.host_setup","title":"Playbook"},{"location":"roles/host_setup/#inventory","text":"Ensure that the target hosts are correctly defined in the inventory:","title":"Inventory"},{"location":"roles/host_setup/#inventoryhostsyml","text":"all: hosts: target_host_1: ansible_host: 192.168.1.100 target_host_2: ansible_host: 192.168.1.101","title":"inventory/hosts.yml"},{"location":"roles/host_setup/#inventorygroup_varsallyml","text":"ansible_user: your_user ansible_ssh_private_key_file: /path/to/ssh/key","title":"inventory/group_vars/all.yml"},{"location":"roles/host_setup/#notes","text":"The role uses the ansible.builtin.package module for installing helm , which ensures compatibility with the package manager of the target operating system. If you require specific Helm versions or additional configurations, you can extend this role or override variables in your playbook or inventory. Test this role using the included tests/test_playbook.yml to verify functionality before deploying to production.","title":"Notes"},{"location":"roles/host_setup/#license","text":"Apache License 2.0","title":"License"},{"location":"roles/install_skupper/","text":"Role: install_skupper This Ansible role automates the installation of Skupper using its Helm chart, ensuring a streamlined and efficient deployment process. Tasks Clone Skupper Repository: Clones the specified Skupper repository and branch to a temporary directory. Install Skupper Using Helm: Deploys Skupper in the specified Kubernetes namespace using the Helm chart. There are two installation modes: cluster and namespace . cluster : Installs Skupper in the entire Kubernetes cluster. The skupper controller namespace needs to be specified in the skupper_namespace variable. namespace : Installs Skupper in a specific namespace. Clean Up Temporary Directory: Removes the cloned repository to maintain a clean environment. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Helm version 3 or newer installed on the control node Git installed on the control node Role Variables Variable Default Value Description install_skupper_skupper_repository https://github.com/skupperproject/skupper.git URL of the Skupper repository. install_skupper_version v2 Branch of the Skupper repository to clone. install_skupper_skupper_release_name skupper-setup Release name for Skupper. install_skupper_install_output_path /tmp/localhost Directory where the repository will be cloned temporarily. install_skupper_scope cluster Scope of the Skupper installation (cluster or namespace). skupper_namespace default Kubernetes namespace for Skupper installation. If cluster , specify the namespace where the Skupper controller will be deployed. Example Usage Playbook - hosts: all tasks: - name: Install Skupper using Helm ansible.builtin.include_role: name: rhsiqe.skupper.install_skupper vars: install_skupper_version: \"v2\" install_skupper_install_output_path: \"/tmp/skupper\" skupper_namespace: \"skupper-namespace\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig install_skupper_install_output_path: \"/tmp/skupper\" skupper_namespace: \"east-namespace\" west.yml kubeconfig: /path/to/west/kubeconfig install_skupper_install_output_path: \"/tmp/skupper\" skupper_namespace: \"west-namespace\" Notes The new Helm-based installation method simplifies the deployment and management of Skupper in Kubernetes clusters. Ensure the kubernetes.core.helm plugin is installed and properly configured on the control node. This role supports Helm version 3 and above, leveraging its capabilities for reliable Kubernetes deployments. The role will check the pods in the specified namespace to ensure that the Skupper controller is running successfully based on the labelSelector=app.kubernetes.io/part-of=skupper License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Install Skupper"},{"location":"roles/install_skupper/#role-install_skupper","text":"This Ansible role automates the installation of Skupper using its Helm chart, ensuring a streamlined and efficient deployment process.","title":"Role: install_skupper"},{"location":"roles/install_skupper/#tasks","text":"Clone Skupper Repository: Clones the specified Skupper repository and branch to a temporary directory. Install Skupper Using Helm: Deploys Skupper in the specified Kubernetes namespace using the Helm chart. There are two installation modes: cluster and namespace . cluster : Installs Skupper in the entire Kubernetes cluster. The skupper controller namespace needs to be specified in the skupper_namespace variable. namespace : Installs Skupper in a specific namespace. Clean Up Temporary Directory: Removes the cloned repository to maintain a clean environment.","title":"Tasks"},{"location":"roles/install_skupper/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Helm version 3 or newer installed on the control node Git installed on the control node","title":"Requirements"},{"location":"roles/install_skupper/#role-variables","text":"Variable Default Value Description install_skupper_skupper_repository https://github.com/skupperproject/skupper.git URL of the Skupper repository. install_skupper_version v2 Branch of the Skupper repository to clone. install_skupper_skupper_release_name skupper-setup Release name for Skupper. install_skupper_install_output_path /tmp/localhost Directory where the repository will be cloned temporarily. install_skupper_scope cluster Scope of the Skupper installation (cluster or namespace). skupper_namespace default Kubernetes namespace for Skupper installation. If cluster , specify the namespace where the Skupper controller will be deployed.","title":"Role Variables"},{"location":"roles/install_skupper/#example-usage","text":"","title":"Example Usage"},{"location":"roles/install_skupper/#playbook","text":"- hosts: all tasks: - name: Install Skupper using Helm ansible.builtin.include_role: name: rhsiqe.skupper.install_skupper vars: install_skupper_version: \"v2\" install_skupper_install_output_path: \"/tmp/skupper\" skupper_namespace: \"skupper-namespace\"","title":"Playbook"},{"location":"roles/install_skupper/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/install_skupper/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig install_skupper_install_output_path: \"/tmp/skupper\" skupper_namespace: \"east-namespace\"","title":"east.yml"},{"location":"roles/install_skupper/#westyml","text":"kubeconfig: /path/to/west/kubeconfig install_skupper_install_output_path: \"/tmp/skupper\" skupper_namespace: \"west-namespace\"","title":"west.yml"},{"location":"roles/install_skupper/#notes","text":"The new Helm-based installation method simplifies the deployment and management of Skupper in Kubernetes clusters. Ensure the kubernetes.core.helm plugin is installed and properly configured on the control node. This role supports Helm version 3 and above, leveraging its capabilities for reliable Kubernetes deployments. The role will check the pods in the specified namespace to ensure that the Skupper controller is running successfully based on the labelSelector=app.kubernetes.io/part-of=skupper","title":"Notes"},{"location":"roles/install_skupper/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/link_site/","text":"Role: link_site The link_site Ansible role establishes a connection between Skupper sites by applying an AccessToken to the target Kubernetes namespace. This enables inter-site communication in a Skupper topology. Tasks Set Namespace and Token Path: Determines the namespace and sets the path to the AccessToken manifest file. Apply AccessToken: Uses the kubernetes.core.k8s module to apply the AccessToken in the target namespace. Debug Application Result: Outputs the results of the applied AccessToken for verification. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig A valid AccessToken manifest available at the specified path Role Variables Variable Default Value Description link_site_access_token_name access-token Name of the AccessToken resource. link_site_target_namespace default Target namespace where the AccessToken will be applied. link_site_access_token_path Path to the AccessToken manifest. Must be defined in playbook/inventory. namespace_prefix Prefix for the namespace. namespace_name Name of the namespace. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. Mandatory. Example Usage Playbook - hosts: all tasks: - name: Link Skupper sites ansible.builtin.include_role: name: rhsiqe.skupper.link_site vars: namespace_prefix: \"skupper\" namespace_name: \"east\" link_site_access_token_path: \"/path/to/east-access-token.yml\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure the link_site_access_token_path variable is defined and points to a valid AccessToken manifest. The role uses the kubernetes.core.k8s module, which requires the kubernetes.core collection to be installed. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Link Site"},{"location":"roles/link_site/#role-link_site","text":"The link_site Ansible role establishes a connection between Skupper sites by applying an AccessToken to the target Kubernetes namespace. This enables inter-site communication in a Skupper topology.","title":"Role: link_site"},{"location":"roles/link_site/#tasks","text":"Set Namespace and Token Path: Determines the namespace and sets the path to the AccessToken manifest file. Apply AccessToken: Uses the kubernetes.core.k8s module to apply the AccessToken in the target namespace. Debug Application Result: Outputs the results of the applied AccessToken for verification.","title":"Tasks"},{"location":"roles/link_site/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig A valid AccessToken manifest available at the specified path","title":"Requirements"},{"location":"roles/link_site/#role-variables","text":"Variable Default Value Description link_site_access_token_name access-token Name of the AccessToken resource. link_site_target_namespace default Target namespace where the AccessToken will be applied. link_site_access_token_path Path to the AccessToken manifest. Must be defined in playbook/inventory. namespace_prefix Prefix for the namespace. namespace_name Name of the namespace. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. Mandatory.","title":"Role Variables"},{"location":"roles/link_site/#example-usage","text":"","title":"Example Usage"},{"location":"roles/link_site/#playbook","text":"- hosts: all tasks: - name: Link Skupper sites ansible.builtin.include_role: name: rhsiqe.skupper.link_site vars: namespace_prefix: \"skupper\" namespace_name: \"east\" link_site_access_token_path: \"/path/to/east-access-token.yml\"","title":"Playbook"},{"location":"roles/link_site/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/link_site/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/link_site/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/link_site/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . Ensure the link_site_access_token_path variable is defined and points to a valid AccessToken manifest. The role uses the kubernetes.core.k8s module, which requires the kubernetes.core collection to be installed.","title":"Notes"},{"location":"roles/link_site/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/run_curl/","text":"Role: run_curl This Ansible role executes a curl command within a Kubernetes cluster using a specified container image. The curl request is run inside a pod created dynamically within a defined namespace. The role ensures retries for pod creation and log retrieval to handle transient issues. Tasks Set Namespace: Constructs the namespace name using a prefix and a base name provided via variables. Run Curl Command: Creates a Kubernetes pod to execute the curl command targeting a specified address. Retrieve Logs: Captures the logs from the pod to output the results of the curl command. Debug Output: Displays the curl output for verification and debugging. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Defaults (from defaults/main.yml ) run_curl_namespace : Default namespace for the pod. (Default: default ) run_curl_address : The target URL for the curl command. (Default: http://example.com ) run_curl_image : The container image used to execute the curl command. (Default: quay.io/rzago/curl-telnet ) run_curl_retries : Number of retry attempts for pod creation. (Default: 10 ) run_curl_delay : Delay in seconds between retries for pod creation. (Default: 10 ) Required Variables These must be defined in the playbook or inventory: namespace_prefix : Prefix for constructing the namespace name. namespace_name : Base name for constructing the namespace. Example Usage Playbook - hosts: all tasks: - name: Run curl command in Kubernetes ansible.builtin.include_role: name: rhsiqe.skupper.run_curl vars: namespace_prefix: \"test\" namespace_name: \"east\" run_curl_address: \"http://my-service.namespace.svc.cluster.local\" Inventory (host_vars) host_vars/east.yml kubeconfig: /path/to/east/kubeconfig namespace_name: east host_vars/west.yml kubeconfig: /path/to/west/kubeconfig namespace_name: west Notes The final namespace is constructed as <namespace_prefix>-<namespace_name> (e.g., test-east ). The run_curl_address should be updated to target the desired service or endpoint in the cluster. The pod created is ephemeral, and its logs are used to capture the curl command output. This role uses the kubernetes.core.k8s and kubernetes.core.k8s_log modules, ensuring a declarative and robust approach for Kubernetes resource management. License Apache License 2.0","title":"Run Curl"},{"location":"roles/run_curl/#role-run_curl","text":"This Ansible role executes a curl command within a Kubernetes cluster using a specified container image. The curl request is run inside a pod created dynamically within a defined namespace. The role ensures retries for pod creation and log retrieval to handle transient issues.","title":"Role: run_curl"},{"location":"roles/run_curl/#tasks","text":"Set Namespace: Constructs the namespace name using a prefix and a base name provided via variables. Run Curl Command: Creates a Kubernetes pod to execute the curl command targeting a specified address. Retrieve Logs: Captures the logs from the pod to output the results of the curl command. Debug Output: Displays the curl output for verification and debugging.","title":"Tasks"},{"location":"roles/run_curl/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/run_curl/#role-variables","text":"","title":"Role Variables"},{"location":"roles/run_curl/#defaults-from-defaultsmainyml","text":"run_curl_namespace : Default namespace for the pod. (Default: default ) run_curl_address : The target URL for the curl command. (Default: http://example.com ) run_curl_image : The container image used to execute the curl command. (Default: quay.io/rzago/curl-telnet ) run_curl_retries : Number of retry attempts for pod creation. (Default: 10 ) run_curl_delay : Delay in seconds between retries for pod creation. (Default: 10 )","title":"Defaults (from defaults/main.yml)"},{"location":"roles/run_curl/#required-variables","text":"These must be defined in the playbook or inventory: namespace_prefix : Prefix for constructing the namespace name. namespace_name : Base name for constructing the namespace.","title":"Required Variables"},{"location":"roles/run_curl/#example-usage","text":"","title":"Example Usage"},{"location":"roles/run_curl/#playbook","text":"- hosts: all tasks: - name: Run curl command in Kubernetes ansible.builtin.include_role: name: rhsiqe.skupper.run_curl vars: namespace_prefix: \"test\" namespace_name: \"east\" run_curl_address: \"http://my-service.namespace.svc.cluster.local\"","title":"Playbook"},{"location":"roles/run_curl/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/run_curl/#host_varseastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_name: east","title":"host_vars/east.yml"},{"location":"roles/run_curl/#host_varswestyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_name: west","title":"host_vars/west.yml"},{"location":"roles/run_curl/#notes","text":"The final namespace is constructed as <namespace_prefix>-<namespace_name> (e.g., test-east ). The run_curl_address should be updated to target the desired service or endpoint in the cluster. The pod created is ephemeral, and its logs are used to capture the curl command output. This role uses the kubernetes.core.k8s and kubernetes.core.k8s_log modules, ensuring a declarative and robust approach for Kubernetes resource management.","title":"Notes"},{"location":"roles/run_curl/#license","text":"Apache License 2.0","title":"License"},{"location":"roles/skupper_site/","text":"Role: skupper_site The skupper_site Ansible role automates the creation and management of Skupper Site resources in a Kubernetes cluster. It generates and applies manifests, ensures resources are correctly deployed, and verifies the readiness of Skupper router pods. Tasks Set Manifest File Path: Determines the output path for the Skupper site manifest. Render Manifest from Template: Creates the Skupper Site resource manifest using a Jinja2 template. Apply Manifest to Kubernetes: Uses the kubernetes.core.k8s module to create or update the Skupper Site resource. Verify Resource Readiness: Checks that all Skupper router pods in the namespace are in a Running state. Debug Results and Pod List: Outputs the results of applied resources and lists running pods for confirmation. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Default Value Description skupper_site_file files/skupper-site.yml Path to the Skupper site manifest file. skupper_site_namespace default Namespace for the Skupper Site resource. skupper_site_state present Desired state of the Site resource ( present or absent ). skupper_site_manifest_template skupper-site.yml.j2 Template for generating the Skupper site manifest. skupper_site_include_spec true Whether to include the spec section in the manifest. skupper_site_link_access default Default value for linkAccess in the site specification. skupper_site_output_path /tmp/localhost Directory where the generated manifest will be stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. Mandatory. Example Usage Playbook - hosts: all tasks: - name: Configure a Skupper site ansible.builtin.include_role: name: rhsiqe.skupper.skupper_site vars: namespace_prefix: \"skupper\" namespace_name: \"east\" skupper_site_link_access: \"public\" skupper_site_output_path: \"/tmp/skupper\" Inventory (host_vars) east.yml kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\" west.yml kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . The manifest file is stored in skupper_site_output_path , named according to the inventory host. Ensure the kubernetes.core.k8s module is installed to use this role. All pods in the namespace are checked to ensure they are in a Running state before completion. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Skupper Site"},{"location":"roles/skupper_site/#role-skupper_site","text":"The skupper_site Ansible role automates the creation and management of Skupper Site resources in a Kubernetes cluster. It generates and applies manifests, ensures resources are correctly deployed, and verifies the readiness of Skupper router pods.","title":"Role: skupper_site"},{"location":"roles/skupper_site/#tasks","text":"Set Manifest File Path: Determines the output path for the Skupper site manifest. Render Manifest from Template: Creates the Skupper Site resource manifest using a Jinja2 template. Apply Manifest to Kubernetes: Uses the kubernetes.core.k8s module to create or update the Skupper Site resource. Verify Resource Readiness: Checks that all Skupper router pods in the namespace are in a Running state. Debug Results and Pod List: Outputs the results of applied resources and lists running pods for confirmation.","title":"Tasks"},{"location":"roles/skupper_site/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/skupper_site/#role-variables","text":"Variable Default Value Description skupper_site_file files/skupper-site.yml Path to the Skupper site manifest file. skupper_site_namespace default Namespace for the Skupper Site resource. skupper_site_state present Desired state of the Site resource ( present or absent ). skupper_site_manifest_template skupper-site.yml.j2 Template for generating the Skupper site manifest. skupper_site_include_spec true Whether to include the spec section in the manifest. skupper_site_link_access default Default value for linkAccess in the site specification. skupper_site_output_path /tmp/localhost Directory where the generated manifest will be stored. namespace_prefix Prefix for the Kubernetes namespace. namespace_name Name of the Kubernetes namespace. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. Mandatory.","title":"Role Variables"},{"location":"roles/skupper_site/#example-usage","text":"","title":"Example Usage"},{"location":"roles/skupper_site/#playbook","text":"- hosts: all tasks: - name: Configure a Skupper site ansible.builtin.include_role: name: rhsiqe.skupper.skupper_site vars: namespace_prefix: \"skupper\" namespace_name: \"east\" skupper_site_link_access: \"public\" skupper_site_output_path: \"/tmp/skupper\"","title":"Playbook"},{"location":"roles/skupper_site/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/skupper_site/#eastyml","text":"kubeconfig: /path/to/east/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"east\"","title":"east.yml"},{"location":"roles/skupper_site/#westyml","text":"kubeconfig: /path/to/west/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"west\"","title":"west.yml"},{"location":"roles/skupper_site/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . The manifest file is stored in skupper_site_output_path , named according to the inventory host. Ensure the kubernetes.core.k8s module is installed to use this role. All pods in the namespace are checked to ensure they are in a Running state before completion.","title":"Notes"},{"location":"roles/skupper_site/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"roles/skupper_test_images/","text":"Role Name This role introduces default values for the supporting images used for testing skupper. Those values can be set as environment variables or overritten per host/or play. The use of those variables in the roles and playbooks should: Allow an easy way to change images without need to changing code Centralize a list of images used by testing, in case they need maintenance Requirements N/A Role Variables See defaults/main.yaml for the actual list. They should all be self-descriptive and have the same function: point to an image on a registry. Dependencies N/A Example Playbook Including the role will have the side-effect of setting the variables. - hosts: localhost roles: - { role: skupper_test_images } License Apache Author Information hash-d","title":"Skupper Test Images"},{"location":"roles/skupper_test_images/#role-name","text":"This role introduces default values for the supporting images used for testing skupper. Those values can be set as environment variables or overritten per host/or play. The use of those variables in the roles and playbooks should: Allow an easy way to change images without need to changing code Centralize a list of images used by testing, in case they need maintenance","title":"Role Name"},{"location":"roles/skupper_test_images/#requirements","text":"N/A","title":"Requirements"},{"location":"roles/skupper_test_images/#role-variables","text":"See defaults/main.yaml for the actual list. They should all be self-descriptive and have the same function: point to an image on a registry.","title":"Role Variables"},{"location":"roles/skupper_test_images/#dependencies","text":"N/A","title":"Dependencies"},{"location":"roles/skupper_test_images/#example-playbook","text":"Including the role will have the side-effect of setting the variables. - hosts: localhost roles: - { role: skupper_test_images }","title":"Example Playbook"},{"location":"roles/skupper_test_images/#license","text":"Apache","title":"License"},{"location":"roles/skupper_test_images/#author-information","text":"hash-d","title":"Author Information"},{"location":"roles/teardown_test/","text":"Role: teardown_test The teardown_test Ansible role removes test environments created during Skupper testing. It deletes the specified namespace, waits for its successful removal, and cleans up temporary directories. Tasks Delete Test Namespace: Deletes the specified Kubernetes namespace using the kubernetes.core.k8s module. Wait for Namespace Deletion: Ensures the namespace is completely removed by checking its absence. Delete Temporary Directories: Removes any temporary directories specified for the test environment. Display Cleanup Summary: Outputs a summary of the deleted resources for verification. Requirements Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig Role Variables Variable Default Value Description namespace_prefix Prefix for the namespace to be deleted. namespace_name Name of the namespace to be deleted. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. teardown_test_temp_dir_path Path to the temporary directory to be deleted. Example Usage Playbook - hosts: all tasks: - name: Teardown test environment ansible.builtin.include_role: name: rhsiqe.skupper.teardown_test vars: namespace_prefix: \"skupper\" namespace_name: \"test\" teardown_test_temp_dir_path: \"/tmp/skupper-test\" Inventory (host_vars) localhost.yml kubeconfig: /path/to/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"test\" teardown_test_temp_dir_path: \"/tmp/skupper-test\" Notes The namespace is derived as <namespace_prefix>-<namespace_name> . The role ensures all resources are cleaned up, including temporary directories used during tests. Ensure the kubernetes.core.k8s module is installed to use this role. Namespace deletion may take some time; the role retries the check for up to 20 attempts with a 2-second delay between each. License This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"Teardown Test"},{"location":"roles/teardown_test/#role-teardown_test","text":"The teardown_test Ansible role removes test environments created during Skupper testing. It deletes the specified namespace, waits for its successful removal, and cleans up temporary directories.","title":"Role: teardown_test"},{"location":"roles/teardown_test/#tasks","text":"Delete Test Namespace: Deletes the specified Kubernetes namespace using the kubernetes.core.k8s module. Wait for Namespace Deletion: Ensures the namespace is completely removed by checking its absence. Delete Temporary Directories: Removes any temporary directories specified for the test environment. Display Cleanup Summary: Outputs a summary of the deleted resources for verification.","title":"Tasks"},{"location":"roles/teardown_test/#requirements","text":"Ansible 2.1 or newer kubernetes.core collection installed on the control node Kubernetes cluster accessible via kubeconfig","title":"Requirements"},{"location":"roles/teardown_test/#role-variables","text":"Variable Default Value Description namespace_prefix Prefix for the namespace to be deleted. namespace_name Name of the namespace to be deleted. kubeconfig Path to the kubeconfig file for accessing the Kubernetes cluster. teardown_test_temp_dir_path Path to the temporary directory to be deleted.","title":"Role Variables"},{"location":"roles/teardown_test/#example-usage","text":"","title":"Example Usage"},{"location":"roles/teardown_test/#playbook","text":"- hosts: all tasks: - name: Teardown test environment ansible.builtin.include_role: name: rhsiqe.skupper.teardown_test vars: namespace_prefix: \"skupper\" namespace_name: \"test\" teardown_test_temp_dir_path: \"/tmp/skupper-test\"","title":"Playbook"},{"location":"roles/teardown_test/#inventory-host_vars","text":"","title":"Inventory (host_vars)"},{"location":"roles/teardown_test/#localhostyml","text":"kubeconfig: /path/to/kubeconfig namespace_prefix: \"skupper\" namespace_name: \"test\" teardown_test_temp_dir_path: \"/tmp/skupper-test\"","title":"localhost.yml"},{"location":"roles/teardown_test/#notes","text":"The namespace is derived as <namespace_prefix>-<namespace_name> . The role ensures all resources are cleaned up, including temporary directories used during tests. Ensure the kubernetes.core.k8s module is installed to use this role. Namespace deletion may take some time; the role retries the check for up to 20 attempts with a 2-second delay between each.","title":"Notes"},{"location":"roles/teardown_test/#license","text":"This project is licensed under the Apache License, Version 2.0. See LICENSE for details.","title":"License"},{"location":"scenarios/hello_world/","text":"Hello World Scenario This hello-world scenario is an example Ansible setup to deploy, connect, and test a distributed application using Skupper. The scenario includes a backend deployed in the east site and a frontend deployed in the west site, connected via Skupper's networking capabilities. Project Structure hello-world \u251c\u2500\u2500 hello-world.yml \u2514\u2500\u2500 inventory \u251c\u2500\u2500 group_vars \u2502 \u2514\u2500\u2500 all.yml \u251c\u2500\u2500 hosts.yml \u2514\u2500\u2500 host_vars \u251c\u2500\u2500 east.yml \u2514\u2500\u2500 west.yml Key Components Playbook ( hello-world.yml ): Configures hosts and performs environment setup, Skupper installation, workload deployment, connectivity testing, and resource cleanup. Inventory : group_vars/all.yml : Global variables shared across hosts. host_vars/east.yml & host_vars/west.yml : Host-specific configurations. Playbook Overview Tasks Host Setup : Prepares the localhost environment. Environment Shakeout : Ensures the environment is ready for deployment. Skupper Installation : Installs Skupper on both sites. Workload Deployment : Backend (east site). Frontend (west site). Connectivity Configuration : Connects the backend to the frontend using Skupper sites, connectors, and listeners. Testing : Validates communication between the frontend and backend using a curl test. Roles rhsiqe.skupper.host_setup : Configures the host. rhsiqe.skupper.install_skupper : Installs Skupper. rhsiqe.skupper.deploy_workload : Deploys backend and frontend workloads. rhsiqe.skupper.link_site : Links Skupper sites for communication. Variables Global Variables ( group_vars/all.yml ) ansible_connection : Defines the connection type (local). namespace_prefix : Prefix for namespace names. debug : Enables debug output. East Site Variables ( host_vars/east.yml ) namespace_name : hello-world-east . Deployment details for the backend application. Connector configuration for exposing the backend. West Site Variables ( host_vars/west.yml ) namespace_name : hello-world-west . Deployment details for the frontend application. Listener configuration for consuming the backend service. Service exposure settings for the frontend. Usage Setup the Environment : Ensure all dependencies are installed, including Ansible and required roles. Run the Playbook : bash ansible-playbook -i inventory/hosts.yml hello-world.yml View Results : Check the deployed workloads. Verify connectivity between the sites. Cleanup The scenario includes a teardown step to delete all test resources, ensuring a clean state for subsequent tests. Notes This scenario demonstrates Skupper's ability to connect services across distributed sites. Adjust variables in inventory as needed to customize for your environment. Contributing Contributions are welcome! Feel free to fork the repository and submit a pull request. License This project is licensed under the Apache 2.0 License .","title":"Hello World"},{"location":"scenarios/hello_world/#hello-world-scenario","text":"This hello-world scenario is an example Ansible setup to deploy, connect, and test a distributed application using Skupper. The scenario includes a backend deployed in the east site and a frontend deployed in the west site, connected via Skupper's networking capabilities.","title":"Hello World Scenario"},{"location":"scenarios/hello_world/#project-structure","text":"hello-world \u251c\u2500\u2500 hello-world.yml \u2514\u2500\u2500 inventory \u251c\u2500\u2500 group_vars \u2502 \u2514\u2500\u2500 all.yml \u251c\u2500\u2500 hosts.yml \u2514\u2500\u2500 host_vars \u251c\u2500\u2500 east.yml \u2514\u2500\u2500 west.yml","title":"Project Structure"},{"location":"scenarios/hello_world/#key-components","text":"Playbook ( hello-world.yml ): Configures hosts and performs environment setup, Skupper installation, workload deployment, connectivity testing, and resource cleanup. Inventory : group_vars/all.yml : Global variables shared across hosts. host_vars/east.yml & host_vars/west.yml : Host-specific configurations.","title":"Key Components"},{"location":"scenarios/hello_world/#playbook-overview","text":"","title":"Playbook Overview"},{"location":"scenarios/hello_world/#tasks","text":"Host Setup : Prepares the localhost environment. Environment Shakeout : Ensures the environment is ready for deployment. Skupper Installation : Installs Skupper on both sites. Workload Deployment : Backend (east site). Frontend (west site). Connectivity Configuration : Connects the backend to the frontend using Skupper sites, connectors, and listeners. Testing : Validates communication between the frontend and backend using a curl test.","title":"Tasks"},{"location":"scenarios/hello_world/#roles","text":"rhsiqe.skupper.host_setup : Configures the host. rhsiqe.skupper.install_skupper : Installs Skupper. rhsiqe.skupper.deploy_workload : Deploys backend and frontend workloads. rhsiqe.skupper.link_site : Links Skupper sites for communication.","title":"Roles"},{"location":"scenarios/hello_world/#variables","text":"","title":"Variables"},{"location":"scenarios/hello_world/#global-variables-group_varsallyml","text":"ansible_connection : Defines the connection type (local). namespace_prefix : Prefix for namespace names. debug : Enables debug output.","title":"Global Variables (group_vars/all.yml)"},{"location":"scenarios/hello_world/#east-site-variables-host_varseastyml","text":"namespace_name : hello-world-east . Deployment details for the backend application. Connector configuration for exposing the backend.","title":"East Site Variables (host_vars/east.yml)"},{"location":"scenarios/hello_world/#west-site-variables-host_varswestyml","text":"namespace_name : hello-world-west . Deployment details for the frontend application. Listener configuration for consuming the backend service. Service exposure settings for the frontend.","title":"West Site Variables (host_vars/west.yml)"},{"location":"scenarios/hello_world/#usage","text":"Setup the Environment : Ensure all dependencies are installed, including Ansible and required roles. Run the Playbook : bash ansible-playbook -i inventory/hosts.yml hello-world.yml View Results : Check the deployed workloads. Verify connectivity between the sites.","title":"Usage"},{"location":"scenarios/hello_world/#cleanup","text":"The scenario includes a teardown step to delete all test resources, ensuring a clean state for subsequent tests.","title":"Cleanup"},{"location":"scenarios/hello_world/#notes","text":"This scenario demonstrates Skupper's ability to connect services across distributed sites. Adjust variables in inventory as needed to customize for your environment.","title":"Notes"},{"location":"scenarios/hello_world/#contributing","text":"Contributions are welcome! Feel free to fork the repository and submit a pull request.","title":"Contributing"},{"location":"scenarios/hello_world/#license","text":"This project is licensed under the Apache 2.0 License .","title":"License"}]}